import pandas as pd
import json

# Path to the log file generated by the consumer script
log_file_path = "1mps-rr3-10i-50ms-v2.csv"  # Change this to your actual log file path
output_json_path = "1mps-rr3-10i-50ms-v2.json"  # Path to save the JSON output

# Load the log file into a Pandas DataFrame, specifying the header if needed
data = pd.read_csv(log_file_path)

# Preview the data to ensure it loaded correctly
print("Data Preview:")
print(data.head())

# Perform Analysis
results = {}

# 1. Calculate the average latency
average_latency = data['Latency'].mean()
print(f"\nAverage Latency: {average_latency:.4f} ms")
results['average_latency'] = average_latency

# 2. Calculate the median latency
median_latency = data['Latency'].median()
print(f"Median Latency: {median_latency:.4f} ms")
results['median_latency'] = median_latency

# 3. Calculate the 99.99th percentile latency
percentile_9999 = data['Latency'].quantile(0.9999)
print(f"99.9999th Percentile Latency: {percentile_9999:.4f} ms")
results['percentile_99.99'] = percentile_9999

# 4. Count the total number of messages that meet the KPI
kpi_met_count = data[data['KPI'] == 'meets KPI'].shape[0]
print(f"Messages Meeting KPI: {kpi_met_count}")
results['messages_meeting_kpi'] = kpi_met_count

# 5. Count the total number of messages that do not meet the KPI
kpi_not_met_count = data[data['KPI'] != 'meets KPI'].shape[0]
print(f"Messages Not Meeting KPI: {kpi_not_met_count}")
results['messages_not_meeting_kpi'] = kpi_not_met_count

# 6. Find the top 5 messages with the highest latency
top_5_latency = data.nlargest(5, 'Latency')
print("\nTop 5 Messages with Highest Latency:")
print(top_5_latency)
results['top_5_highest_latency'] = top_5_latency.to_dict(orient='records')

# Save results to a JSON file
with open(output_json_path, 'w') as json_file:
    json.dump(results, json_file, indent=4)

print(f"\nAnalysis results saved to {output_json_path}")

